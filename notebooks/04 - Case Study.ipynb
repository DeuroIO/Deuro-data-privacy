{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Case Study - Privacy in Practice\n",
    "\n",
    "In this notebook, we'll explore the possibilties for data privacy on a new dataset. In this notebook, you'll be asked to work in small groups, so make friends with someone seated near you. \n",
    "\n",
    "Your challenge is that you are working with a health care provider, who would like to do the \"machine learning\" on this dataset to figure out if there are preventative measures that can be taken so fewer patients are seen in the hospital for related care or so that their visits are shorter. The goal is that more potentially affected patients are given access to primary care physicians and regular medication or visits that can keep them out of the hostpital for long stays. This study is focused on blood-sugar related illnesses, but not only diabetes.\n",
    "\n",
    "Using this dataset, we'll walk through a few possible scenarios and apply what we have learned today about data privacy to this new use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Determining What's Useful and What's Sensitive\n",
    "\n",
    "- Data completeness\n",
    "- Potential sensitive columns\n",
    "- Potential useful features\n",
    "- What should we use (or not use)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/health_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.admitted_ts = df.admitted_ts.map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S') + timedelta(days=-8*12*30) if datetime.strptime(x, '%Y-%m-%d %H:%M:%S').year > 2018 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/health_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you'd like, continue to look at column distributions, values or feel free to plot a few which are of interest to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "\n",
    "- What columns should we use? \n",
    "- Which ones should we remove?\n",
    "- Are there columns which we should protect but not remove? \n",
    "\n",
    "For each, we need some justification or thought!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['id', 'patient_name', 'ssn']\n",
    "\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Determining the Approach for Protecting the Columns\n",
    "\n",
    "- Scenario One: You are an employee of the company which produced this data. You have full access and can use full variables for building your model; however, you want to respect privacy and ensure your model is valuable without leaking private information.\n",
    "\n",
    "- Scenario Two: You are the database manager at the health care provider asked to prepare the data to send to a machine learning consultant who will help give you a more detailed analysis. The consultant has signed all the necessary NDAs, but you have instructions to keep the private or potentially sensitive data to a minimum.\n",
    "\n",
    "- Scenario Three: You suggested releasing the dataset to Kaggle. It will be uploaded so hundreds of Kagglers can participate. For the sake of avoiding a long legal argument, let's say all patients were part of a study in which they signed a waiver that their records could be released publicly. That said, you still want to avoid a PR nightmare and protect the data as much as possible. \n",
    "\n",
    "Based on the scenario for your team above, what do you do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any investigation code to see what approach you might use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.private_insurance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.no_primary_dr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['no_primary_dr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.marital_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.hist(bins=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- What methods will be most effective in the scenario you have? \n",
    "- Have you considered potential data leakage within the *non-sensitive* columns?\n",
    "- Is there other sensitive or secret data we should address given the scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Three: Implement Data Protection for the Dataset\n",
    "\n",
    "Now it's time to code! Feel free to utilize code from the previous notebooks to implement protection of at least two of the columns you chose as sensitive. Are there ways to make these applications more Pandas-friendly or easy to use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement protection for the columns you are keeping -- you may use code from previous notebooks in this workshop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario three: possible implementation (to hide as solution for hints)\n",
    "\n",
    "\n",
    "## pseudonymize hospital, age and admitted timestamp\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "SHARED_KEY = '42a2d3fc1cc449e2a27ddd457e056012'\n",
    "\n",
    "item_list = list(df.T.to_dict().values())\n",
    "\n",
    "actions = [\n",
    "    {\n",
    "        \"name\": \"pseudonymize-hospital\",\n",
    "        \"transform-value\" : {\n",
    "            \"key\": \"hospital\",\n",
    "            \"pseudonymize\" : {\n",
    "                \"method\": \"merengue\",\n",
    "                \"key\": \"89f7dklnvkldhiwokdljklsnm,qip72\", \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pseudonymize-age\",\n",
    "        \"transform-value\": {\n",
    "            \"key\": \"age\",\n",
    "            \"pseudonymize\": {\n",
    "                \"method\": \"structured\",\n",
    "                \"key\": \"320fidsjkl8wy8uiofme#908\",\n",
    "                \"type\": \"integer\",\n",
    "                \"format\": \"raw\",\n",
    "                \"typeParams\": {\n",
    "                    \"min\": 16,\n",
    "                    \"max\": 100\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pseudonymize-admitted-ts\",\n",
    "        \"transform-value\": {\n",
    "            \"key\": \"admitted_ts\",\n",
    "            \"pseudonymize\": {\n",
    "                \"method\": \"structured\",\n",
    "                \"key\": \"320fidsjkl8wy8uiofme#908\",\n",
    "                \"type\": \"date\",\n",
    "                \"preservePrefix\": True,\n",
    "                \"format\": \"%(2000-2019)Y-%m-%d %H:%M:%S\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pseudonymized_data = requests.post(\n",
    "    'https://api.kiprotect.com/v1/transform', \n",
    "    data = json.dumps(\n",
    "        {\"actions\": actions, \"items\": item_list}, \n",
    "        allow_nan=False),\n",
    "    headers = {'Authorization': 'Bearer {}'.format(\n",
    "        SHARED_KEY)}\n",
    ")\n",
    "\n",
    "\n",
    "protected_df = pd.DataFrame(pseudonymized_data.json()['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add differentially private for cols private_insurance or no_primary_dr and has_diabetes\n",
    "#Possible next step, explore k-anon?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "- What was difficult to decide and implement?\n",
    "- How might this relate to real problems in machine learning with sensitive data? \n",
    "- Does this apply to your work? How? What can you take away?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_df.to_csv('../data/health_data_protected.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
